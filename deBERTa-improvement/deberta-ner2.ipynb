{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"TRAINING_MODEL_PATH = \"microsoft/deberta-v3-base\"\nTRAINING_MAX_LENGTH = 1024\nSTRIDE = 200\nOUTPUT_DIR = \"output\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:47:35.548722Z","iopub.execute_input":"2024-12-22T11:47:35.549039Z","iopub.status.idle":"2024-12-22T11:47:35.552649Z","shell.execute_reply.started":"2024-12-22T11:47:35.549012Z","shell.execute_reply":"2024-12-22T11:47:35.551710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install seqeval evaluate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:47:35.871796Z","iopub.execute_input":"2024-12-22T11:47:35.872073Z","iopub.status.idle":"2024-12-22T11:47:43.260137Z","shell.execute_reply.started":"2024-12-22T11:47:35.872052Z","shell.execute_reply":"2024-12-22T11:47:43.259217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport argparse\nfrom itertools import chain\nfrom functools import partial\n\nimport torch\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\nimport evaluate\nfrom datasets import Dataset, features\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:47:43.261616Z","iopub.execute_input":"2024-12-22T11:47:43.261922Z","iopub.status.idle":"2024-12-22T11:47:59.557251Z","shell.execute_reply.started":"2024-12-22T11:47:43.261893Z","shell.execute_reply":"2024-12-22T11:47:59.556447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n\n# downsampling of negative examples\np=[] # positive samples (contain relevant labels)\nn=[] # negative samples (presumably contain entities that are possibly wrongly classified as entity)\nfor d in data:\n    if any(np.array(d[\"labels\"]) != \"O\"): p.append(d)\n    else: n.append(d)\nprint(\"original datapoints: \", len(data))\n\n# external = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/pii_dataset_fixed.json\"))\n# print(\"external datapoints: \", len(external))\n\n# moredata = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/moredata_dataset_fixed.json\"))\n# print(\"moredata datapoints: \", len(moredata))\n\n# data = moredata+external+p+n[:len(n)//3]\ndata = p+n[:len(n)//3]\nprint(\"combined: \", len(data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:47:59.559029Z","iopub.execute_input":"2024-12-22T11:47:59.559596Z","iopub.status.idle":"2024-12-22T11:48:02.484537Z","shell.execute_reply.started":"2024-12-22T11:47:59.559570Z","shell.execute_reply":"2024-12-22T11:48:02.483496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\nlabel2id = {l: i for i,l in enumerate(all_labels)}\nid2label = {v:k for k,v in label2id.items()}\n\ntarget = [\n    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n]\n\nprint(id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:02.485955Z","iopub.execute_input":"2024-12-22T11:48:02.486297Z","iopub.status.idle":"2024-12-22T11:48:02.516319Z","shell.execute_reply.started":"2024-12-22T11:48:02.486266Z","shell.execute_reply":"2024-12-22T11:48:02.515411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize(example, tokenizer, label2id, max_length):\n\n    # rebuild text from tokens\n    text = []\n    labels = []\n\n    for t, l, ws in zip(\n        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n    ):\n        text.append(t)\n        labels.extend([l] * len(t))\n\n        if ws:\n            text.append(\" \")\n            labels.append(\"O\")\n\n    # actual tokenization\n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True,\n                          truncation=False)\n\n    labels = np.array(labels)\n\n    text = \"\".join(text)\n    token_labels = []\n\n    for start_idx, end_idx in tokenized.offset_mapping:\n        # CLS token\n        if start_idx == 0 and end_idx == 0:\n            token_labels.append(label2id[\"O\"])\n            continue\n\n        # case when token starts with whitespace\n        if text[start_idx].isspace():\n            start_idx += 1\n\n        token_labels.append(label2id[labels[start_idx]])\n\n    length = len(tokenized.input_ids)\n\n    return {**tokenized, \"labels\": token_labels, \"length\": length}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:02.517110Z","iopub.execute_input":"2024-12-22T11:48:02.517353Z","iopub.status.idle":"2024-12-22T11:48:02.534823Z","shell.execute_reply.started":"2024-12-22T11:48:02.517332Z","shell.execute_reply":"2024-12-22T11:48:02.533928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize(example, tokenizer, label2id, max_length):\n\n    # rebuild text from tokens\n    text = []\n    labels = []\n\n    for t, l, ws in zip(\n        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n    ):\n        text.append(t)\n        labels.extend([l] * len(t))\n\n        if ws:\n            text.append(\" \")\n            labels.append(\"O\")\n\n    # actual tokenization\n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True,\n                          truncation=False)\n\n    labels = np.array(labels)\n\n    text = \"\".join(text)\n    token_labels = []\n\n    for start_idx, end_idx in tokenized.offset_mapping:\n        # CLS token\n        if start_idx == 0 and end_idx == 0:\n            token_labels.append(label2id[\"O\"])\n            continue\n\n        # case when token starts with whitespace\n        if text[start_idx].isspace():\n            start_idx += 1\n\n        token_labels.append(label2id[labels[start_idx]])\n\n    length = len(tokenized.input_ids)\n\n    return {**tokenized, \"labels\": token_labels, \"length\": length}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:02.535626Z","iopub.execute_input":"2024-12-22T11:48:02.535855Z","iopub.status.idle":"2024-12-22T11:48:02.549828Z","shell.execute_reply.started":"2024-12-22T11:48:02.535834Z","shell.execute_reply":"2024-12-22T11:48:02.548883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n\nds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data],\n    \"document\": [str(x[\"document\"]) for x in data],\n    \"tokens\": [x[\"tokens\"] for x in data],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n    \"provided_labels\": [x[\"labels\"] for x in data],\n})\nds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id,\n                                 \"max_length\": TRAINING_MAX_LENGTH}, num_proc=3)\n# ds = ds.class_encode_column(\"group\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:02.550616Z","iopub.execute_input":"2024-12-22T11:48:02.550845Z","iopub.status.idle":"2024-12-22T11:48:18.984771Z","shell.execute_reply.started":"2024-12-22T11:48:02.550825Z","shell.execute_reply":"2024-12-22T11:48:18.983939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = ds[0]\n\nfor t,l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n    if l != \"O\":\n        print((t,l))\n\nprint(\"*\"*100)\n\nfor t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n    if id2label[l] != \"O\":\n        print((t,id2label[l]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:18.987557Z","iopub.execute_input":"2024-12-22T11:48:18.987792Z","iopub.status.idle":"2024-12-22T11:48:19.001858Z","shell.execute_reply.started":"2024-12-22T11:48:18.987770Z","shell.execute_reply":"2024-12-22T11:48:19.001185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def backwards_map_preds(sub_predictions, max_len):\n    if max_len != 1: # nothing to map backwards if sequence is too short to be split in the first place\n        if i == 0:\n            # First sequence needs no SEP token (used to end a sequence)\n            sub_predictions = sub_predictions[:,:-1,:]\n        elif i == max_len-1:\n            # End sequence needs to CLS token + Stride tokens \n            sub_predictions = sub_predictions[:,1+STRIDE:,:] # CLS tokens + Stride tokens\n        else:\n            # Middle sequence needs to CLS token + Stride tokens + SEP token\n            sub_predictions = sub_predictions[:,1+STRIDE:-1,:]\n    return sub_predictions\n\ndef backwards_map_(row_attribute, max_len):\n    # Same logics as for backwards_map_preds - except lists instead of 3darray\n    if max_len != 1:\n        if i == 0:\n            row_attribute = row_attribute[:-1]\n        elif i == max_len-1:\n            row_attribute = row_attribute[1+STRIDE:]\n        else:\n            row_attribute = row_attribute[1+STRIDE:-1]\n    return row_attribute","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:19.002798Z","iopub.execute_input":"2024-12-22T11:48:19.003096Z","iopub.status.idle":"2024-12-22T11:48:19.019255Z","shell.execute_reply.started":"2024-12-22T11:48:19.003068Z","shell.execute_reply":"2024-12-22T11:48:19.018464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from seqeval.metrics import recall_score, precision_score\nfrom seqeval.metrics import classification_report\nfrom seqeval.metrics import f1_score\n\ndef compute_metrics(p, all_labels):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    \n    recall = recall_score(true_labels, true_predictions)\n    precision = precision_score(true_labels, true_predictions)\n    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n    \n    results = {\n        'recall': recall,\n        'precision': precision,\n        'f1': f1_score\n    }\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:19.020161Z","iopub.execute_input":"2024-12-22T11:48:19.020368Z","iopub.status.idle":"2024-12-22T11:48:19.043232Z","shell.execute_reply.started":"2024-12-22T11:48:19.020349Z","shell.execute_reply":"2024-12-22T11:48:19.042516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    TRAINING_MODEL_PATH,\n    num_labels=len(all_labels),\n    id2label=id2label,\n    label2id=label2id,\n    ignore_mismatched_sizes=True\n)\ncollator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:19.044065Z","iopub.execute_input":"2024-12-22T11:48:19.044289Z","iopub.status.idle":"2024-12-22T11:48:22.887246Z","shell.execute_reply.started":"2024-12-22T11:48:19.044260Z","shell.execute_reply":"2024-12-22T11:48:22.886572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=OUTPUT_DIR, \n    fp16=True,\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=2,\n    report_to=\"none\",\n    evaluation_strategy=\"no\",\n    do_eval=False,\n    save_total_limit=1,\n    logging_steps=20,\n    lr_scheduler_type='cosine',\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n    warmup_ratio=0.1,\n    weight_decay=0.01\n)\n\ntrainer = Trainer(\n    model=model, \n    args=args, \n    train_dataset=ds,\n    data_collator=collator, \n    tokenizer=tokenizer,\n    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:22.888116Z","iopub.execute_input":"2024-12-22T11:48:22.888477Z","iopub.status.idle":"2024-12-22T11:48:23.378742Z","shell.execute_reply.started":"2024-12-22T11:48:22.888449Z","shell.execute_reply":"2024-12-22T11:48:23.378012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:48:23.379507Z","iopub.execute_input":"2024-12-22T11:48:23.379743Z","iopub.status.idle":"2024-12-22T11:56:12.115935Z","shell.execute_reply.started":"2024-12-22T11:48:23.379722Z","shell.execute_reply":"2024-12-22T11:56:12.114963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.save_model(\"deberta3base_1024\")\ntokenizer.save_pretrained(\"deberta3base_1024\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T11:56:12.116765Z","iopub.execute_input":"2024-12-22T11:56:12.116976Z","iopub.status.idle":"2024-12-22T11:56:14.263630Z","shell.execute_reply.started":"2024-12-22T11:56:12.116958Z","shell.execute_reply":"2024-12-22T11:56:14.262835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}